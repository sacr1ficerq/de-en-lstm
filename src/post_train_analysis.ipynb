{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "config = {\n",
    "    'model_name': 'LSTM_2',\n",
    "    'feature': 'regularized',\n",
    "    'max_len': 48,\n",
    "    'min_freq_src': 5,\n",
    "    'min_freq_trg': 4,\n",
    "    \n",
    "    'src_vocab_size': 24992,\n",
    "    'trg_vocab_size': 21555,\n",
    "\n",
    "    'embedding_dim': 128,\n",
    "    'hidden_size': 256,\n",
    "    'num_layers': 2,\n",
    "\n",
    "    'num_epochs': 18,\n",
    "    'weight_decay': 1e-5,\n",
    "    'label_smoothing': 0.1,\n",
    "    'dropout': 0.2,\n",
    "\n",
    "    'learning_rate': 1e-3,\n",
    "    'gamma': 0.2,\n",
    "    'patience': 0,\n",
    "    'threshold': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TranslationDataset, Vocab, TrainDataLoader, TestDataLoader\n",
    "from config import filenames, folders\n",
    "from lstm2 import LSTM_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sds'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195915/195915 [00:13<00:00, 14458.21it/s]\n",
      "100%|██████████| 986/986 [00:00<00:00, 15177.01it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_src = Vocab(filenames['train_src'], min_freq=config['min_freq_src'])\n",
    "vocab_trg = Vocab(filenames['train_trg'], min_freq=config['min_freq_trg'])\n",
    "\n",
    "train_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['train_src'], \n",
    "                                filenames['train_trg'], \n",
    "                                max_len=config['max_len'], \n",
    "                                device=device)\n",
    "\n",
    "val_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['test_src'], \n",
    "                                filenames['test_trg'], \n",
    "                                max_len=72, \n",
    "                                device=device, \n",
    "                                sort_lengths=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24992 21555\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_src), len(vocab_trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_2(\n",
      "  (src_embedding): Embedding(30249, 128)\n",
      "  (trg_embedding): Embedding(21950, 128)\n",
      "  (encoder): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (encoder_output_proj): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (decoder): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (encoder_hidden_proj): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (encoder_cell_proj): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=21950, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "unk_idx, pad_idx, bos_idx, eos_idx = 0, 1, 2, 3\n",
    "\n",
    "train_loader = TrainDataLoader(train_dataset, shuffle=True)\n",
    "val_loader = TestDataLoader(val_dataset, shuffle=False)\n",
    "\n",
    "weights_filename = folders['weights'] + 'lstm-save-14.pt'\n",
    "\n",
    "model = LSTM_2(config=config, weights_filename=weights_filename).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load('../weights/train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submission import get_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:05<00:17,  5.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mget_bleu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_trg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\Desktop\\bhw2\\src\\submission.py:34\u001b[39m, in \u001b[36mget_bleu\u001b[39m\u001b[34m(model, dataloader, vocab_trg, filenames, device)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m src, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m         predictions = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# batch\u001b[39;00m\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(src)):\n\u001b[32m     36\u001b[39m             pred_text = vocab_trg.decode(predictions[i], ignore=no_unk)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\Desktop\\bhw2\\src\\lstm2.py:287\u001b[39m, in \u001b[36mLSTM_2.inference\u001b[39m\u001b[34m(self, src_seq, max_len, device)\u001b[39m\n\u001b[32m    284\u001b[39m context = torch.bmm(attention, encoder_outputs)\n\u001b[32m    285\u001b[39m combined = torch.cat([decoder_output, context], dim=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, 1, trg_vocab_size)\u001b[39;00m\n\u001b[32m    288\u001b[39m logits[:, :, unk_idx] = -\u001b[32m1e10\u001b[39m\n\u001b[32m    289\u001b[39m next_token = logits.argmax(dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "get_bleu(model, val_loader, vocab_trg, filenames, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('lstm-deep-cut-vocab-12epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:59<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from submission import make_submission\n",
    "from dataset import SubmissionDataset, SubmissionDataLoader\n",
    "submission_dataset = SubmissionDataset(filenames['submission_src'], vocab_src, device=device)\n",
    "ldr = SubmissionDataLoader(submission_dataset)\n",
    "make_submission(model, ldr, vocab_trg, filenames, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
