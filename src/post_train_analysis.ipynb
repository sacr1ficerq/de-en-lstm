{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "config = {\n",
    "    'model_name': 'LSTM_2',\n",
    "    'feature': 'regularized',\n",
    "    'max_len': 48,\n",
    "    'min_freq_src': 4,\n",
    "    'min_freq_trg': 4,\n",
    "\n",
    "    'embedding_dim': 128,\n",
    "    'hidden_size': 256,\n",
    "    'num_epochs': 15,\n",
    "    'weight_decay': 1e-5,\n",
    "    'label_smoothing': 0.1,\n",
    "    'dropout': 0.2,\n",
    "\n",
    "    'learning_rate': 1e-3,\n",
    "    'gamma': 0.2,\n",
    "    'patience': 0,\n",
    "    'threshold': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195915/195915 [00:24<00:00, 7996.68it/s]\n",
      "100%|██████████| 986/986 [00:00<00:00, 8507.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_2(\n",
      "  (src_embedding): Embedding(30249, 128)\n",
      "  (trg_embedding): Embedding(21950, 128)\n",
      "  (encoder): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (encoder_output_proj): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (decoder): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (encoder_hidden_proj): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (encoder_cell_proj): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=21950, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from dataset import TranslationDataset, Vocab, TrainDataLoader, TestDataLoader\n",
    "from config import filenames, folders\n",
    "from lstm2 import LSTM_2\n",
    "\n",
    "\n",
    "vocab_src = Vocab(filenames['train_src'], min_freq=config['min_freq_src'])\n",
    "vocab_trg = Vocab(filenames['train_trg'], min_freq=config['min_freq_trg'])\n",
    "\n",
    "train_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['train_src'], \n",
    "                                filenames['train_trg'], \n",
    "                                max_len=config['max_len'], \n",
    "                                device=device)\n",
    "\n",
    "val_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['test_src'], \n",
    "                                filenames['test_trg'], \n",
    "                                max_len=72, \n",
    "                                device=device, \n",
    "                                sort_lengths=True)\n",
    "\n",
    "unk_idx, pad_idx, bos_idx, eos_idx = 0, 1, 2, 3\n",
    "\n",
    "train_loader = TrainDataLoader(train_dataset, shuffle=True)\n",
    "val_loader = TestDataLoader(val_dataset)\n",
    "\n",
    "src_vocab_size = len(vocab_src)\n",
    "trg_vocab_size = len(vocab_trg)\n",
    "\n",
    "model = LSTM_2(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    trg_vocab_size=trg_vocab_size,\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    hidden_size=config['hidden_size'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('lstm-save-14.pt', folders['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=weight_decay)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, patience=2, factor=gamma, verbose=True, threshold=1e-3)\n",
    "# train_losses, val_losses = train(model, \n",
    "#                                  optimizer, \n",
    "#                                  num_epochs, \n",
    "#                                  train_loader, \n",
    "#                                  test_loader, \n",
    "#                                  criterion, \n",
    "#                                  vocab_trg, \n",
    "#                                  scheduler)\n",
    "# plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submission import get_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "get_bleu(model, val_loader, vocab_trg, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('lstm-deep-cut-vocab-12epoch.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'submission_filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msubmission\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_submission\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SubmissionDataset, SubmissionDataLoader\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m submission_dataset = SubmissionDataset(\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msubmission_filename\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, vocab_src, device=device)\n\u001b[32m      4\u001b[39m ldr = SubmissionDataLoader(submission_dataset)\n\u001b[32m      5\u001b[39m make_submission(model, ldr, vocab_trg, device=device)\n",
      "\u001b[31mKeyError\u001b[39m: 'submission_filename'"
     ]
    }
   ],
   "source": [
    "from submission import make_submission\n",
    "from dataset import SubmissionDataset, SubmissionDataLoader\n",
    "submission_dataset = SubmissionDataset(filenames['submission'], vocab_src, device=device)\n",
    "ldr = SubmissionDataLoader(submission_dataset)\n",
    "make_submission(model, ldr, vocab_trg, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
