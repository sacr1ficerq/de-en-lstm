{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "config = {\n",
    "    'model_name': 'LSTM_3',\n",
    "    'feature': 'testing-teacher-forcing',\n",
    "    'max_len': 42,\n",
    "    'min_freq_src': 5,\n",
    "    'min_freq_trg': 5,\n",
    "    \n",
    "    'src_vocab_size': 24991,\n",
    "    'trg_vocab_size': 18710,\n",
    "\n",
    "    'embedding_dim': 128,\n",
    "    'hidden_size': 256,\n",
    "    'num_layers': 3,\n",
    "\n",
    "    'num_epochs': 15,\n",
    "    'weight_decay': 1e-5,\n",
    "    'label_smoothing': 0.1,\n",
    "\n",
    "    'dropout_enc': 0.1,\n",
    "    'dropout_dec': 0.1,\n",
    "    'dropout_emb': 0.1,\n",
    "    'dropout_attention': 0.1,\n",
    "\n",
    "    'learning_rate': 1e-3,\n",
    "    'gamma': 0.2,\n",
    "    'patience': 2,\n",
    "    'threshold': 5e-4,\n",
    "    'batch_size': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TranslationDataset, Vocab, TrainDataLoader, TestDataLoader\n",
    "from config import filenames, folders\n",
    "from lstm3 import LSTM_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195915/195915 [00:12<00:00, 15432.21it/s]\n",
      "100%|██████████| 986/986 [00:00<00:00, 15688.98it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_src = Vocab(filenames['train_src'], min_freq=config['min_freq_src'])\n",
    "vocab_trg = Vocab(filenames['train_trg'], min_freq=config['min_freq_trg'])\n",
    "\n",
    "train_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['train_src'], \n",
    "                                filenames['train_trg'], \n",
    "                                max_len=config['max_len'], \n",
    "                                device=device)\n",
    "\n",
    "val_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['test_src'], \n",
    "                                filenames['test_trg'], \n",
    "                                max_len=72, \n",
    "                                device=device, \n",
    "                                sort_lengths=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24991 18710\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_src), len(vocab_trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_3(\n",
      "  (src_embedding): Embedding(24991, 128, padding_idx=1)\n",
      "  (trg_embedding): Embedding(18710, 128, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (enc_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (dec_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (encoder): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (encoder_output_proj): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (decoder): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (encoder_hidden_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (encoder_cell_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=18710, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "unk_idx, pad_idx, bos_idx, eos_idx = 0, 1, 2, 3\n",
    "\n",
    "train_loader = TrainDataLoader(train_dataset, shuffle=True)\n",
    "val_loader = TestDataLoader(val_dataset, shuffle=False)\n",
    "\n",
    "weights_filename = folders['weights'] + 'lstm-save-15.pt'\n",
    "\n",
    "model = LSTM_3(config=config, weights_filename=weights_filename).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.98365283, 8.00939226, 7.99636304, 7.95958185, 8.03385913,\n",
       "       8.08714366, 5.78621149, 5.70957637, 5.64270401, 5.58472025,\n",
       "       5.5331763 , 5.47639728, 5.42644572, 5.33323669, 5.34423482])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load('../weights/train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submission import get_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import RawDataset\n",
    "raw_dataset = RawDataset(filenames['test_src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:12<00:00,  3.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "get_bleu(model, dataloader=val_loader, vocab_trg=vocab_trg, filenames=filenames, device=device, raw_dataset=raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('lstm-deep-cut-vocab-12epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "val_loader = TestDataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "for src_seq, _ in val_loader:\n",
    "    batch_size = src_seq.size(1)\n",
    "    trg_seq = torch.tensor([[bos_idx]] * batch_size, dtype=torch.long).to(device)  # (batch_size, 1)\n",
    "    print(batch_size)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'years'"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_trg.decode_idx(18611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 21 17\n",
      "als ich <NUM> jahre alt war , wurde ich eines morgens von den klängen heller freude geweckt .\n",
      "when i was <NUM> , i remember waking up one morning to the sound of joy in my house .\n",
      "i was <NUM> years , i was one morning\n",
      "17 15 15\n",
      "mein vater hörte sich auf seinem kleinen , grauen radio die der bbc an .\n",
      "my father was listening to bbc news on his small , gray radio .\n",
      "father was on his ,\n",
      "20 21 17\n",
      "er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens .\n",
      "there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
      "he very happy\n",
      "11 12 9\n",
      "er rief : \" die taliban sind weg ! \"\n",
      "\" the taliban are gone ! \" my father .\n",
      "said , \" the taliban are gone !\n",
      "20 22 17\n",
      "ich wusste nicht , was das bedeutete , aber es machte meinen vater offensichtlich sehr , sehr glücklich .\n",
      "i didn 't know what it meant , but i could see that my father was very , very happy .\n",
      "didn 't know what it meant but\n",
      "15 15 12\n",
      "\" jetzt kannst du auf eine richtige schule gehen , \" sagte er .\n",
      "\" you can go to a real school now , \" he said .\n",
      "now you can go to a school\n",
      "8 9 7\n",
      "diesen morgen werde ich niemals vergessen .\n",
      "a morning that i will never forget .\n",
      "tomorrow i never\n",
      "5 5 5\n",
      "eine richtige schule .\n",
      "a real school .\n",
      "'s a school .\n",
      "24 24 19\n",
      "die taliban ergriffen die macht in afghanistan , als ich sechs war , und verboten es mädchen , zur schule zu gehen .\n",
      "you see , i was six when the taliban took over afghanistan and made it illegal for girls to go to school .\n",
      "taliban took power in afghanistan when was\n",
      "28 34 24\n",
      "deshalb ich mich fünf jahre lang als junge und begleitete meine ältere schwester , die nicht mehr alleine ausgehen durfte , zu einer geheimen schule .\n",
      "so for the next five years , i dressed as a boy to my older sister , who was no longer allowed to be outside alone , to a secret school .\n",
      "i why i for years\n",
      "10 12 11\n",
      "nur so konnten wir beide zur schule gehen .\n",
      "it was the only way we both could be educated .\n",
      "that just that we\n",
      "18 20 17\n",
      "jeden tag nahmen wir einen anderen weg , sodass niemand erraten konnte , wohin wir gingen .\n",
      "each day , we took a different route so that no one would suspect where we were going .\n",
      "day\n",
      "20 19 17\n",
      "wir versteckten unsere bücher in , damit es so aussah , als würden wir nur einkaufen gehen .\n",
      "we would cover our books in grocery bags so it would seem we were just out shopping .\n",
      "hid our books in so\n",
      "16 20 14\n",
      "unterrichtet wurden wir in einem haus , über <NUM> mädchen in einem kleinen wohnzimmer .\n",
      "the school was in a house , more than <NUM> of us packed in one small living room .\n",
      "were in\n",
      "15 12 14\n",
      "im winter war es gemütlich , aber im sommer war es unglaublich heiß .\n",
      "it was cozy in winter but extremely hot in summer .\n",
      "winter , it was , but in , summer it was incredibly hot\n",
      "18 19 17\n",
      "wir alle wussten , dass wir unser leben : lehrer , schüler und unsere eltern .\n",
      "we all knew we were risking our lives -- the teacher , the students and our parents .\n",
      "all knew that we\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[461]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(vocab_trg.decode(trg[i])))\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(vocab_trg.decode(predictions[i])))\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "val_loader = TestDataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "for src_seq, _ in val_loader:\n",
    "    batch_size = src_seq.size(1)\n",
    "    trg_seq = torch.tensor([[bos_idx]] * batch_size, dtype=torch.long).to(device)  # (batch_size, 1)\n",
    "    # print(batch_size)\n",
    "    break\n",
    "from time import sleep\n",
    "for batch_idx, (src, trg) in enumerate(val_loader):\n",
    "    predictions = model.inference(src, device=device) # batch\n",
    "    for i in range(len(src)):\n",
    "        print(list(src[i]).index(eos_idx),list(trg[i]).index(eos_idx), list(predictions[i]).index(eos_idx))\n",
    "        print(\"src:\\t\", \" \".join(vocab_src.decode(src[i])))\n",
    "        print(\"trg:\\t\", \" \".join(vocab_trg.decode(trg[i])))\n",
    "        print(\"pred:\\t\", \" \".join(vocab_trg.decode(predictions[i])))\n",
    "        sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_submission = RawDataset(filenames['submission_src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m submission_dataset = SubmissionDataset(filenames[\u001b[33m'\u001b[39m\u001b[33msubmission_src\u001b[39m\u001b[33m'\u001b[39m], vocab_src, device=device)\n\u001b[32m      4\u001b[39m ldr = SubmissionDataLoader(submission_dataset)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m make_submission(model, ldr, vocab_trg, filenames, device=device, raw_dataset=\u001b[43mraw_submission\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'raw_submission' is not defined"
     ]
    }
   ],
   "source": [
    "from submission import make_submission\n",
    "from dataset import SubmissionDataset, SubmissionDataLoader\n",
    "submission_dataset = SubmissionDataset(filenames['submission_src'], vocab_src, device=device)\n",
    "ldr = SubmissionDataLoader(submission_dataset)\n",
    "make_submission(model, ldr, vocab_trg, filenames, device=device, raw_dataset=raw_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg = val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import TestDataLoader\n",
    "ldr = TestDataLoader(val_dataset, batch_size=2)\n",
    "src, trg = ldr[0]\n",
    "src.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  8125, 18184,     4, 18611,  8125, 18184, 18184, 11593, 10819,\n",
       "         10819, 10819, 10819, 10819, 16813, 11529, 16813, 11529,    32,    32,\n",
       "            32,    32,     3],\n",
       "        [    2,  6209, 18184, 11587,  7839,    28,  9758,    28,    28,  1543,\n",
       "            28,    28, 13407, 16813, 16813, 11529, 16813, 11529, 16813,    32,\n",
       "             3,     3,     3]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.inference(src, device='cpu')\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'was', '<NUM>', 'years', 'i', 'was']\n",
      "<BOS> i was <NUM> years i was was one morning morning morning morning morning the of the of . . . . <EOS> "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "trg_words = ['<BOS>', 'i', 'was', '<NUM>', 'years', 'i', 'was']\n",
    "i = len(trg_words) - 1\n",
    "trg_pred = torch.tensor([vocab_trg.encode_word(word) for word in trg_words], dtype=torch.long).unsqueeze(0)\n",
    "predictions = model.inference(src, device='cpu')\n",
    "print(vocab_trg.decode(trg_pred.squeeze(0).numpy()))\n",
    "for idx in predictions[0]:\n",
    "    print(vocab_trg.decode_idx(idx.item()), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'was',\n",
       " '<NUM>',\n",
       " 'years',\n",
       " 'i',\n",
       " 'was',\n",
       " 'was',\n",
       " 'one',\n",
       " 'morning',\n",
       " 'morning',\n",
       " 'morning',\n",
       " 'morning',\n",
       " 'morning',\n",
       " 'the',\n",
       " 'of',\n",
       " 'the',\n",
       " 'of',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_trg.decode(model.inference(src, device='cpu').squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,  8125, 18184,     4, 18611,  8125, 18184])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_pred.squeeze(0).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
