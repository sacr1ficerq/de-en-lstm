{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195915/195915 [00:29<00:00, 6606.84it/s]\n",
      "100%|██████████| 986/986 [00:00<00:00, 6328.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name\n",
      "feature\n",
      "max_len\n",
      "min_freq_src\n",
      "min_freq_trg\n",
      "embedding_dim\n",
      "hidden_size\n",
      "num_layers\n",
      "num_epochs\n",
      "weight_decay\n",
      "label_smoothing\n",
      "dropout_emb\n",
      "dropout_enc\n",
      "dropout_dec\n",
      "dropout_attention\n",
      "learning_rate\n",
      "gamma\n",
      "patience\n",
      "threshold\n",
      "batch_size\n",
      "use_tf\n",
      "tf_from_epoch\n",
      "tf_start\n",
      "tf_decrease\n",
      "src_vocab_size\n",
      "trg_vocab_size\n"
     ]
    }
   ],
   "source": [
    "print(*config, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<dataset.Vocab at 0x1df44902900>,\n",
       " <dataset.Vocab at 0x1df20202850>,\n",
       " <dataset.TranslationDataset at 0x1df44902a50>,\n",
       " <dataset.TranslationDataset at 0x1df448af4d0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_src, vocab_trg, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TrainDataLoader, TestDataLoader\n",
    "from config import filenames, folders\n",
    "from lstm3 import LSTM_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_3(\n",
      "  (src_embedding): Embedding(24991, 120, padding_idx=1)\n",
      "  (trg_embedding): Embedding(18710, 120, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (enc_dropout): Dropout(p=0.4, inplace=True)\n",
      "  (dec_dropout): Dropout(p=0.4, inplace=True)\n",
      "  (attention_dropout): Dropout(p=0.1, inplace=True)\n",
      "  (encoder): LSTM(120, 360, num_layers=3, batch_first=True, dropout=0.4, bidirectional=True)\n",
      "  (encoder_output_proj): Linear(in_features=720, out_features=360, bias=True)\n",
      "  (decoder): LSTM(120, 360, num_layers=3, batch_first=True, dropout=0.4)\n",
      "  (encoder_hidden_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=720, out_features=360, bias=True)\n",
      "  )\n",
      "  (encoder_cell_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=720, out_features=360, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=720, out_features=18710, bias=True)\n",
      ")\n",
      "30944870\n"
     ]
    }
   ],
   "source": [
    "unk_idx, pad_idx, bos_idx, eos_idx = 0, 1, 2, 3\n",
    "device = 'cuda'\n",
    "\n",
    "train_loader = TrainDataLoader(train_dataset, shuffle=True)\n",
    "val_loader = TestDataLoader(val_dataset, shuffle=False)\n",
    "\n",
    "weights_filename = folders['weights'] + 'LSTM_3-even-more-regularization-30.0m-15epoch.pt'\n",
    "\n",
    "model = LSTM_3(config=config, weights_filename=weights_filename).to(device)\n",
    "print(model)\n",
    "print(model.count_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.40982389, 3.8720361 , 3.65585768, 3.5329634 , 3.48615831,\n",
       "       3.42260098, 3.40424037, 3.37793773, 3.34819674, 3.36216146,\n",
       "       3.34456837, 3.34149617, 3.34147906, 3.35454029, 3.34359002])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load('../weights/train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submission import get_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import RawDataset\n",
    "raw_dataset = RawDataset(filenames['test_trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisions: [66.42670214 40.53904846 27.31464309 18.03492617]\n",
      "precisions_cnt: [986. 986. 986. 986.]\n",
      "avg bleu: 0.3004379914545143\n",
      "penalties: 0.8852650415023444\n",
      "bleu4: 27.10981744421907\n",
      "sacrebleu ../data/val.de-en.en --tokenize none --width 2 -b -i ../submission/val_pred.en\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.89"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(model, dataloader=val_loader, vocab_trg=vocab_trg, filenames=filenames, device=device, raw_dataset=raw_dataset, use_beam=True, beam_width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:30<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from submission import make_submission\n",
    "from dataset import SubmissionDataLoader, SubmissionDataset\n",
    "raw_dataset = RawDataset(filenames['submission_src'])\n",
    "submission_dataset = SubmissionDataset(filenames['submission_src'], vocab=vocab_src)\n",
    "submission_loader = SubmissionDataLoader(submission_dataset)\n",
    "make_submission(model, submission_loader=submission_loader, raw_dataset=raw_dataset, vocab_trg=vocab_trg, filenames=filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "for a, b in val_dataset:\n",
    "    print(a.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_bleu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_trg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab_trg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:17\u001b[39m, in \u001b[36mget_bleu\u001b[39m\u001b[34m(model, dataloader, vocab_trg, filenames, raw_dataset, use_beam, beam_width, device)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\Desktop\\bhw2\\src\\dataset.py:99\u001b[39m, in \u001b[36mVocab.decode\u001b[39m\u001b[34m(self, idxs, ignore, src)\u001b[39m\n\u001b[32m     97\u001b[39m         has_num = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     98\u001b[39m         nums_idxs.append(i)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     result.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode_idx\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    100\u001b[39m     i += \u001b[32m1\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_num \u001b[38;5;129;01mand\u001b[39;00m src != \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\Desktop\\bhw2\\src\\dataset.py:71\u001b[39m, in \u001b[36mVocab.decode_idx\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m num_idx\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vocab[word] \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vocab \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vocab[\u001b[33m'\u001b[39m\u001b[33m<UNK>\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_idx\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.all_words[idx]\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, words, max_len=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "get_bleu(model, dataloader=val_loader, vocab_trg=vocab_trg, filenames=filenames, device=device, raw_dataset=raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submission import bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg = val_dataset[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we were scared , but we wanted to go to school .'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab_trg.decode(model.inference(src.unsqueeze(0)).squeeze(0)))\n",
    "\" \".join(vocab_trg.decode(trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45       0.21052632 0.05555556 0.02941176]\n",
      "[45.         21.05263158  5.55555556  2.94117647]\n",
      "0.8607079764250579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.6"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu(vocab_trg.decode(model.inference(src.unsqueeze(0)).squeeze(0)), vocab_trg.decode(trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "19 21 17 18\n",
      "src:\t\t als ich <NUM> jahre alt war , wurde ich eines morgens von den klängen heller freude geweckt .\n",
      "trg:\t\t when i was <NUM> , i remember waking up one morning to the sound of joy in my house .\n",
      "pred:\t\t when i was <NUM> years old , i was told one morning by the bright ,\n",
      "0.24\n",
      "pred-beam:\t when i was <NUM> years old , i was told by the sounds of the noises .\n",
      "0.17\n",
      "\n",
      "17 15 14 16\n",
      "src:\t\t mein vater hörte sich auf seinem kleinen , grauen radio die der bbc an .\n",
      "trg:\t\t my father was listening to bbc news on his small , gray radio .\n",
      "pred:\t\t my father was clinging to his little , gray radio\n",
      "0.07\n",
      "pred-beam:\t my dad listened to his little , radio , the little radio waves .\n",
      "0\n",
      "\n",
      "20 21 18 22\n",
      "src:\t\t er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens .\n",
      "trg:\t\t there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
      "pred:\t\t he looked very happy , which was quite unusual , because it 's the news mostly .\n",
      "0.17\n",
      "pred-beam:\t he looked very happy , which was quite unusual at the time , which was quite unusual at the time .\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.demonstrate(val_loader, vocab_src, vocab_trg, device='cuda', examples=3, wait=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_precisions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m ref = \u001b[33m\"\u001b[39m\u001b[33mthere was a big smile on his face which was unusual then , because the news mostly depressed him .\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m pred = \u001b[33m\"\u001b[39m\u001b[33mhe looked very happy , which was quite unusual , because it \u001b[39m\u001b[33m'\u001b[39m\u001b[33ms the news mostly .\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mbleu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m, in \u001b[36mbleu\u001b[39m\u001b[34m(ref, c)\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'get_precisions' is not defined"
     ]
    }
   ],
   "source": [
    "from submission import bleu, get_precisions\n",
    "ref = \"there was a big smile on his face which was unusual then , because the news mostly depressed him .\"\n",
    "pred = \"he looked very happy , which was quite unusual , because it 's the news mostly .\"\n",
    "bleu(ref.split(), pred.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_submission = RawDataset(filenames['submission_src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submission import make_submission\n",
    "from dataset import SubmissionDataset, SubmissionDataLoader\n",
    "submission_dataset = SubmissionDataset(filenames['submission_src'], vocab_src, device=device)\n",
    "ldr = SubmissionDataLoader(submission_dataset)\n",
    "# make_submission(model, ldr, vocab_trg, filenames, device=device, raw_dataset=raw_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg = val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TestDataLoader\n",
    "ldr = TestDataLoader(val_dataset, batch_size=2)\n",
    "src, trg = ldr[0]\n",
    "src.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "trg_words = ['<BOS>', 'i', 'was', '<NUM>', 'years', 'i', 'was']\n",
    "i = len(trg_words) - 1\n",
    "trg_pred = torch.tensor([vocab_trg.encode_word(word) for word in trg_words], dtype=torch.long).unsqueeze(0)\n",
    "predictions = model.inference(src, device='cpu')\n",
    "print(vocab_trg.decode(trg_pred.squeeze(0).numpy()))\n",
    "for idx in predictions[0]:\n",
    "    print(vocab_trg.decode_idx(idx.item()), end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
