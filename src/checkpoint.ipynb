{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset2 import TranslationDataset, Vocab\n",
    "from submission import get_bleu\n",
    "import torch\n",
    "\n",
    "from config import filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to ../\n",
      "Extracted files: ['test1.de-en.de', 'train.de-en.de', 'train.de-en.en', 'val.de-en.de', 'val.de-en.en']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = '../bhw2-data.zip'\n",
    "extract_to = '../'\n",
    "data_folder = extract_to + 'data/'\n",
    "train_src_filename = data_folder + 'train.de-en.de'\n",
    "train_trg_filename = data_folder + 'train.de-en.en'\n",
    "test_src_filename = data_folder + 'val.de-en.de'\n",
    "test_trg_filename = data_folder + 'val.de-en.en'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "print(f\"Files extracted to {extract_to}\")\n",
    "print(\"Extracted files:\", os.listdir(data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset2 import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_src = Vocab(filenames['train_src'], min_freq=5)\n",
    "vocab_trg = Vocab(filenames['train_trg'], min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24461\n",
      "18144\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_src))\n",
    "print(len(vocab_trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_src.max_freq_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'avcs'\n",
    "len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'ich bin nba schpiler'.split()\n",
    "trg = 'i want to play in nba'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56752"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_src.word_counter['ich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_src.check_sub('nba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_seq = vocab_src.encode(src)\n",
    "trg_seq = vocab_trg.encode(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "['nba']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'want', 'to', 'play', 'in', 'nba']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_trg.decode(trg_seq, src=src, vocab_src=vocab_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 48392/195915 [00:08<00:25, 5843.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_dataset = \u001b[43mTranslationDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mvocab_trg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mtrain_src_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mtrain_trg_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m test_dataset = TranslationDataset(vocab_src, \n\u001b[32m      8\u001b[39m                                   vocab_trg, \n\u001b[32m      9\u001b[39m                                   test_src_filename, \n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m                                   device=device, \n\u001b[32m     13\u001b[39m                                   sort_lengths=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\Desktop\\bhw2\\src\\dataset.py:102\u001b[39m, in \u001b[36mTranslationDataset.__init__\u001b[39m\u001b[34m(self, vocab_src, vocab_trg, filename_src, filename_trg, max_len, device, sort_lengths)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(word_sentences_src))):\n\u001b[32m    101\u001b[39m     new_src = vocab_src.encode(word_sentences_src[i], max_len)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     new_src = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     sentences_src.append(new_src)\n\u001b[32m    105\u001b[39m     new_trg = vocab_trg.encode(word_sentences_trg[i], max_len)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_dataset = TranslationDataset(vocab_src, \n",
    "                                   vocab_trg, \n",
    "                                   train_src_filename, \n",
    "                                   train_trg_filename, \n",
    "                                   max_len=64, \n",
    "                                   device=device)\n",
    "test_dataset = TranslationDataset(vocab_src, \n",
    "                                  vocab_trg, \n",
    "                                  test_src_filename, \n",
    "                                  test_trg_filename, \n",
    "                                  max_len=72, \n",
    "                                  device=device, \n",
    "                                  sort_lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 10700, 14316, 15972, 18322, 20704,  3977,  7637,    15,  7876,\n",
      "        36391, 22284,    39,     3], device='cuda:0')\n",
      "tensor([    2, 23615,  1849, 15907,  1685, 13823, 23615,    35,  8570, 23582,\n",
      "        13823, 23580, 25556,  3471,    39,     3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(*train_dataset[110], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15\n",
      "29 36\n",
      "24 25\n",
      "23 24\n",
      "18 24\n",
      "21 20\n",
      "9 8\n",
      "17 15\n",
      "18 18\n",
      "20 21\n",
      "11 10\n",
      "23 25\n",
      "10 9\n",
      "7 10\n",
      "29 25\n",
      "12 12\n",
      "10 10\n",
      "17 22\n",
      "10 9\n",
      "34 41\n"
     ]
    }
   ],
   "source": [
    "for i, (src, trg) in enumerate(train_dataset):\n",
    "    if i % 10_000 == 0:\n",
    "        print(len(src), len(trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TrainDataLoader, TestDataLoader\n",
    "unk_idx, pad_idx, bos_idx, eos_idx = 0, 1, 2, 3\n",
    "\n",
    "train_loader = TrainDataLoader(train_dataset, shuffle=True)\n",
    "test_loader = TestDataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def clear_cache(model):\n",
    "    model.cpu()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 48]) torch.Size([64, 48])\n",
      "torch.Size([64, 48]) torch.Size([64, 48])\n",
      "torch.Size([64, 48]) torch.Size([64, 48])\n",
      "torch.Size([64, 48]) torch.Size([64, 48])\n",
      "torch.Size([64, 48]) torch.Size([64, 48])\n",
      "torch.Size([64, 44]) torch.Size([64, 43])\n",
      "torch.Size([64, 48]) torch.Size([64, 48])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "   if i% 500 == 0:\n",
    "      print(batch[0].size(), batch[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_cache(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_2(\n",
      "  (src_embedding): Embedding(38465, 64)\n",
      "  (trg_embedding): Embedding(26257, 64)\n",
      "  (encoder): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.15, bidirectional=True)\n",
      "  (encoder_output_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (decoder): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.15)\n",
      "  (encoder_hidden_proj): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (encoder_cell_proj): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=26257, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dubinin Daniil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from lstm2 import LSTM_2, train, plot_losses\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "src_vocab_size = len(vocab_src)\n",
    "trg_vocab_size = len(vocab_trg)\n",
    "embedding_dim = 64\n",
    "hidden_size = 128\n",
    "learning_rate = 5e-3\n",
    "gamma = 0.1\n",
    "num_epochs = 12\n",
    "weight_decay = 1e-5\n",
    "label_smoothing = 0.1\n",
    "\n",
    "model = LSTM_2(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    trg_vocab_size=trg_vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    dropout=0.15\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx, label_smoothing=label_smoothing)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=2, factor=gamma, verbose=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTM_2:\n\tsize mismatch for src_embedding.weight: copying a param with shape torch.Size([25379, 64]) from checkpoint, the shape in current model is torch.Size([38465, 64]).\n\tsize mismatch for trg_embedding.weight: copying a param with shape torch.Size([19057, 64]) from checkpoint, the shape in current model is torch.Size([26257, 64]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([19057, 256]) from checkpoint, the shape in current model is torch.Size([26257, 256]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([19057]) from checkpoint, the shape in current model is torch.Size([26257]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# train_losses, val_losses = train(model, optimizer, num_epochs, train_loader, test_loader, criterion, trg_vocab_size, scheduler)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# print(*torch.load('lstm-regularized-12epoch.pt').keys(), sep='\\n')\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlstm-regularized-cut-vocab-10epoch.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m train_losses, val_losses = model.train_loss, model.val_loss\n\u001b[32m      5\u001b[39m plot_losses(train_losses, val_losses)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\Desktop\\bhw2\\src\\lstm2.py:188\u001b[39m, in \u001b[36mLSTM_2.load\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28mself\u001b[39m.train_loss = np.load(\u001b[33m'\u001b[39m\u001b[33mtrain.npy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    187\u001b[39m \u001b[38;5;28mself\u001b[39m.val_loss = np.load(\u001b[33m'\u001b[39m\u001b[33mval.npy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dubinin Daniil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2581\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2573\u001b[39m         error_msgs.insert(\n\u001b[32m   2574\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2575\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2576\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2577\u001b[39m             ),\n\u001b[32m   2578\u001b[39m         )\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2583\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2584\u001b[39m         )\n\u001b[32m   2585\u001b[39m     )\n\u001b[32m   2586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for LSTM_2:\n\tsize mismatch for src_embedding.weight: copying a param with shape torch.Size([25379, 64]) from checkpoint, the shape in current model is torch.Size([38465, 64]).\n\tsize mismatch for trg_embedding.weight: copying a param with shape torch.Size([19057, 64]) from checkpoint, the shape in current model is torch.Size([26257, 64]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([19057, 256]) from checkpoint, the shape in current model is torch.Size([26257, 256]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([19057]) from checkpoint, the shape in current model is torch.Size([26257])."
     ]
    }
   ],
   "source": [
    "# train_losses, val_losses = train(model, optimizer, num_epochs, train_loader, test_loader, criterion, trg_vocab_size, scheduler)\n",
    "# print(*torch.load('lstm-regularized-12epoch.pt').keys(), sep='\\n')\n",
    "model.load('lstm-regularized-cut-vocab-10epoch.pt')\n",
    "train_losses, val_losses = model.train_loss, model.val_loss\n",
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.90864683 2.87150702 2.56812275 2.4015559  2.29022142 2.20895368\n",
      " 2.14491234 2.09421665 2.05214971 2.01697366 1.98539129 1.95969942] [2.92919451 2.57247037 2.47399157 2.40769878 2.38161317 2.37686232\n",
      " 2.35697159 2.36191532 2.35576686 2.36135063 2.36614612 2.3800391 ]\n"
     ]
    }
   ],
   "source": [
    "print(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results0 = {\n",
    "    'model' : 'LSTM(num_layers=2, dropout=0.1, embdeing_dim=64)',\n",
    "    'oprimizer': 'Adam(lr=0.001)',\n",
    "    'train loss': 1.6788,\n",
    "    'val loss': 2.3845,\n",
    "    'bleu4 local, public': (24.61, 20.36),\n",
    "    'parameteres': 15459071,\n",
    "    'epochs': 11,\n",
    "    'weight_file': 'weights/lstm-11epochs.pt',\n",
    "    'time/epoch, total time': '~3m, ~40m',\n",
    "    'vocab sizes': (55315, 34047)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1309727638.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m'bleu4 local, public': (, ),\u001b[39m\n                            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "results1 = {\n",
    "    'model' : 'LSTM(num_layers=2, dropout=0.15, embdeing_dim=64)',\n",
    "    'oprimizer': 'AdamW(lr=5e-3, weight_decay=1e-5)',\n",
    "    'train loss': 1.95969942,\n",
    "    'val loss': 2.3800391,\n",
    "    'bleu4 local, public': (15.87, ),\n",
    "    'parameteres': ,\n",
    "    'epochs': 12,\n",
    "    'weight_file': 'weights/lstm-11epochs.pt',\n",
    "    'time/epoch, total time': '3m 10s, 40m',\n",
    "    'vocab sizes': (38465, 34047)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SubmissionDataset, SubmissionDataLoader\n",
    "\n",
    "val_filename = data_folder + 'test1.de-en.de'\n",
    "\n",
    "submission_dataset = SubmissionDataset(val_filename, vocab_src)\n",
    "submission_loader = SubmissionDataLoader(submission_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.36"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(model, test_loader, vocab_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:18<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from submission import make_submission\n",
    "make_submission(model, submission_loader, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LSTM_Deep(\n",
       "  (src_embedding): Embedding(55315, 64)\n",
       "  (trg_embedding): Embedding(34047, 64)\n",
       "  (encoder): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (encoder_output_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (decoder): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (encoder_hidden_proj): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (encoder_cell_proj): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=34047, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
