{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm3 import train\n",
    "\n",
    "from config import filenames, folders\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "config = {\n",
    "    'model_name': 'LSTM_3',\n",
    "    'feature': 'testing-teacher-forcing',\n",
    "    # 'max_len': 48,\n",
    "    'max_len': 24,\n",
    "    'min_freq_src': 4,\n",
    "    'min_freq_trg': 4,\n",
    "    \n",
    "    'src_vocab_size': 29798,\n",
    "    'trg_vocab_size': 21555,\n",
    "\n",
    "    # 'embedding_dim': 128,\n",
    "    # 'hidden_size': 256,\n",
    "    # 'num_layers': 3,\n",
    "\n",
    "    'embedding_dim': 64,\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 2,\n",
    "\n",
    "    'num_epochs': 15,\n",
    "    'weight_decay': 1e-5,\n",
    "    'label_smoothing': 0.1,\n",
    "\n",
    "    'dropout_enc': 0.1,\n",
    "    'dropout_dec': 0.1,\n",
    "    'dropout_emb': 0.1,\n",
    "    'dropout_attention': 0.1,\n",
    "\n",
    "    'learning_rate': 1e-3,\n",
    "    'gamma': 0.2,\n",
    "    'patience': 2,\n",
    "    'threshold': 5e-4,\n",
    "    'batch_size': 128\n",
    "}\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Vocab\n",
    "vocab_src = Vocab(filenames['train_src'], min_freq=config['min_freq_src'])\n",
    "vocab_trg = Vocab(filenames['train_trg'], min_freq=config['min_freq_trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TranslationDataset\n",
    "train_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['train_src'], \n",
    "                                filenames['train_trg'], \n",
    "                                max_len=config['max_len'], \n",
    "                                device=device)\n",
    "val_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['test_src'], \n",
    "                                filenames['test_trg'], \n",
    "                                max_len=72, \n",
    "                                device=device, \n",
    "                                sort_lengths=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195915/195915 [00:36<00:00, 5333.92it/s]\n",
      "100%|██████████| 986/986 [00:00<00:00, 5215.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_3(\n",
      "  (src_embedding): Embedding(29798, 64, padding_idx=1)\n",
      "  (trg_embedding): Embedding(21555, 64, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (enc_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (dec_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (encoder): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (encoder_output_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (decoder): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (encoder_hidden_proj): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (encoder_cell_proj): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=21555, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 378/1531 [01:16<03:49,  5.03it/s]"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(config=config, \n",
    "                                 filenames=filenames, \n",
    "                                 folders=folders, \n",
    "                                 use_wandb=False, \n",
    "                                 device=device, \n",
    "                                 vocab_src=vocab_src, \n",
    "                                 vocab_trg=vocab_trg,\n",
    "                                 )\n",
    "\n",
    "plot_losses(train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
