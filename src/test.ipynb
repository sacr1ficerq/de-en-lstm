{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm3 import train\n",
    "\n",
    "from config import filenames, folders\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "config = {\n",
    "    'model_name': 'LSTM_3',\n",
    "    'feature': 'testing-teacher-forcing',\n",
    "    'max_len': 42,\n",
    "    # 'max_len': 24,\n",
    "    'min_freq_src': 5,\n",
    "    'min_freq_trg': 5,\n",
    "    \n",
    "    'src_vocab_size': 24991,\n",
    "    'trg_vocab_size': 18710,\n",
    "\n",
    "    'embedding_dim': 128,\n",
    "    'hidden_size': 256,\n",
    "    'num_layers': 3,\n",
    "\n",
    "    # 'embedding_dim': 64,\n",
    "    # 'hidden_size': 128,\n",
    "    # 'num_layers': 2,\n",
    "\n",
    "    'num_epochs': 15,\n",
    "    'weight_decay': 1e-5,\n",
    "    'label_smoothing': 0.1,\n",
    "\n",
    "    'dropout_enc': 0.1,\n",
    "    'dropout_dec': 0.1,\n",
    "    'dropout_emb': 0.1,\n",
    "    'dropout_attention': 0.1,\n",
    "\n",
    "    'learning_rate': 1e-3,\n",
    "    'gamma': 0.2,\n",
    "    'patience': 2,\n",
    "    'threshold': 5e-4,\n",
    "    'batch_size': 128\n",
    "}\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Vocab\n",
    "vocab_src = Vocab(filenames['train_src'], min_freq=config['min_freq_src'])\n",
    "vocab_trg = Vocab(filenames['train_trg'], min_freq=config['min_freq_trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24991\n",
      "18710\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_src))\n",
    "print(len(vocab_trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195915/195915 [00:41<00:00, 4755.82it/s]\n",
      "100%|██████████| 986/986 [00:00<00:00, 4469.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from dataset import TranslationDataset\n",
    "train_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['train_src'], \n",
    "                                filenames['train_trg'], \n",
    "                                max_len=config['max_len'], \n",
    "                                device=device)\n",
    "val_dataset = TranslationDataset(vocab_src, \n",
    "                                vocab_trg, \n",
    "                                filenames['test_src'], \n",
    "                                filenames['test_trg'], \n",
    "                                max_len=72, \n",
    "                                device=device, \n",
    "                                sort_lengths=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_3(\n",
      "  (src_embedding): Embedding(24991, 128, padding_idx=1)\n",
      "  (trg_embedding): Embedding(18710, 128, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (enc_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (dec_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (encoder): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (encoder_output_proj): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (decoder): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (encoder_hidden_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (encoder_cell_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=18710, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1531/1531 [03:47<00:00,  6.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15]\tTrain Loss: 5.2859\tVal Loss: 7.9641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 326/1531 [00:58<03:51,  5.21it/s]"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(config=config, \n",
    "                                 filenames=filenames, \n",
    "                                 folders=folders, \n",
    "                                 use_wandb=False, \n",
    "                                 device=device, \n",
    "                                 vocab_src=vocab_src, \n",
    "                                 vocab_trg=vocab_trg,\n",
    "                                 train_dataset=train_dataset,\n",
    "                                 val_dataset=val_dataset)\n",
    "\n",
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195915/195915 [00:30<00:00, 6329.81it/s]\n",
      "100%|██████████| 986/986 [00:00<00:00, 5973.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_2(\n",
      "  (src_embedding): Embedding(24991, 128, padding_idx=1)\n",
      "  (trg_embedding): Embedding(18710, 128, padding_idx=1)\n",
      "  (encoder): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (encoder_output_proj): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (decoder): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (encoder_hidden_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (encoder_cell_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=18710, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1531 [01:05<4:09:37,  9.82s/it]"
     ]
    }
   ],
   "source": [
    "# lstm-2\n",
    "train_losses, val_losses = train(config=config, \n",
    "                                 filenames=filenames, \n",
    "                                 folders=folders, \n",
    "                                 use_wandb=False, \n",
    "                                 device=device)\n",
    "\n",
    "plot_losses(train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
